{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-1Z5yISSMCpd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input image\n",
        "image = cv2.imread('/content/35cmx45cm.JPG')\n",
        "image = cv2.resize(image, (720, 640))\n"
      ],
      "metadata": {
        "id": "SSpvTYmVMGRd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Models and set mean values\n",
        "face1 = \"opencv_face_detector.pbtxt\"\n",
        "face2 = \"opencv_face_detector_uint8.pb\"\n",
        "age1 = \"age_deploy.prototxt\"\n",
        "age2 = \"age_net.caffemodel\"\n",
        "gen1 = \"gender_deploy.prototxt\"\n",
        "gen2 = \"gender_net.caffemodel\"\n",
        "\n",
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "\n",
        "# Using models\n",
        "# Face\n",
        "face = cv2.dnn.readNet(face2, face1)\n",
        "\n",
        "# age\n",
        "age = cv2.dnn.readNet(age2, age1)\n",
        "\n",
        "# gender\n",
        "gen = cv2.dnn.readNet(gen2, gen1)\n"
      ],
      "metadata": {
        "id": "y842czIQMw_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories of distribution\n",
        "la = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
        "\t'(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
        "lg = ['Male', 'Female']\n"
      ],
      "metadata": {
        "id": "FrtpwHSjMNNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy image\n",
        "fr_cv = image.copy()\n"
      ],
      "metadata": {
        "id": "2hKcvwqRMPlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Face detection\n",
        "fr_h = fr_cv.shape[0]\n",
        "fr_w = fr_cv.shape[1]\n",
        "blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300),\n",
        "\t\t\t\t\t\t\t[104, 117, 123], True, False)\n",
        "\n",
        "face.setInput(blob)\n",
        "detections = face.forward()\n"
      ],
      "metadata": {
        "id": "nBkXKVX-MSm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Face bounding box creation\n",
        "faceBoxes = []\n",
        "for i in range(detections.shape[2]):\n",
        "\n",
        "\t#Bounding box creation if confidence > 0.7\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\tif confidence > 0.7:\n",
        "\n",
        "\t\tx1 = int(detections[0, 0, i, 3]*fr_w)\n",
        "\t\ty1 = int(detections[0, 0, i, 4]*fr_h)\n",
        "\t\tx2 = int(detections[0, 0, i, 5]*fr_w)\n",
        "\t\ty2 = int(detections[0, 0, i, 6]*fr_h)\n",
        "\n",
        "\t\tfaceBoxes.append([x1, y1, x2, y2])\n",
        "\n",
        "\t\tcv2.rectangle(fr_cv, (x1, y1), (x2, y2),\n",
        "\t\t\t\t\t(0, 255, 0), int(round(fr_h/150)), 8)\n",
        "\n",
        "faceBoxes\n"
      ],
      "metadata": {
        "id": "4vf5fyRDMUgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if face detected or not\n",
        "if not faceBoxes:\n",
        "\tprint(\"No face detected\")\n",
        "\n",
        "# Final results (otherwise)\n",
        "# Loop for all the faces detected\n",
        "for faceBox in faceBoxes:\n",
        "\n",
        "\t#Extracting face as per the faceBox\n",
        "\tface = fr_cv[max(0, faceBox[1]-15):\n",
        "\t\t\t\tmin(faceBox[3]+15, fr_cv.shape[0]-1),\n",
        "\t\t\t\tmax(0, faceBox[0]-15):min(faceBox[2]+15,\n",
        "\t\t\t\t\t\t\tfr_cv.shape[1]-1)]\n",
        "\n",
        "\t#Extracting the main blob part\n",
        "\tblob = cv2.dnn.blobFromImage(\n",
        "\t\tface, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "\n",
        "\t#Prediction of gender\n",
        "\tgen.setInput(blob)\n",
        "\tgenderPreds = gen.forward()\n",
        "\tgender = lg[genderPreds[0].argmax()]\n",
        "\n",
        "\t#Prediction of age\n",
        "\tage.setInput(blob)\n",
        "\tagePreds = age.forward()\n",
        "\tage = la[agePreds[0].argmax()]\n",
        "\n",
        "\t#Putting text of age and gender\n",
        "\t#At the top of box\n",
        "\tcv2.putText(fr_cv,\n",
        "\t\t\t\tf'{gender}, {age}',\n",
        "\t\t\t\t(faceBox[0]-150, faceBox[1]+10),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t\t\t1.3,\n",
        "\t\t\t\t(217, 0, 0),\n",
        "\t\t\t\t4,\n",
        "\t\t\t\tcv2.LINE_AA)\n",
        "\n",
        "\tplt.figure(figsize=(7, 7))\n",
        "\tplt.imshow(fr_cv)\n"
      ],
      "metadata": {
        "id": "Yuyvz0nuMXQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}